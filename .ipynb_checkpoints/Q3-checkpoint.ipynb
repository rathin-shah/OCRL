{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ac3f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Documents/Spring2023/OCRL/HW1_S23/OCRL/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "using LinearAlgebra, Plots\n",
    "import ForwardDiff as FD\n",
    "using Printf\n",
    "using JLD2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142245b",
   "metadata": {},
   "source": [
    "## Q2 (20 pts): Augmented Lagrangian Quadratic Program Solver\n",
    "\n",
    "Here we are going to use the augmented lagrangian method described [here in a video](https://www.youtube.com/watch?v=0x0JD5uO_ZQ), with [the corresponding pdf here](https://github.com/Optimal-Control-16-745/lecture-notebooks-2022/blob/main/misc/AL_tutorial.pdf) to solve the following problem:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\min_x \\quad & \\frac{1}{2}x^TQx + q^Tx \\\\ \n",
    "\\mbox{s.t.}\\quad &  Ax -b = 0 \\\\ \n",
    "&  Gx - h \\leq 0 \n",
    "\\end{align}$$\n",
    "where the cost function is described by $Q \\in \\mathbb{R}^{n \\times n}$, $q \\in \\mathbb{R}^n$, an equality constraint is described by $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^m$, and an inequality constraint is described by $G \\in \\mathbb{R}^{p \\times n}$ and $h \\in \\mathbb{R}^p$.\n",
    "\n",
    "\n",
    "By introducing a dual variable $\\lambda \\in \\mathbb{R}^m$ for the equality constraint, and $\\mu \\in \\mathbb{R}^p$ for the inequality constraint, we have the following KKT conditions for optimality:\n",
    "\n",
    "$$\\begin{align}\n",
    "Qx + q + A^T\\lambda + G^T \\mu &= 0 \\quad \\quad \\text{stationarity}\\\\ \n",
    "Ax-b&= 0 \\quad \\quad \\text{primal feasibility} \\\\ \n",
    "Gx-h&\\leq 0 \\quad \\quad \\text{primal feasibility} \\\\ \n",
    "\\mu &\\geq 0 \\quad \\quad \\text{dual feasibility} \\\\ \n",
    "\\mu \\circ (Gx - h) &= 0 \\quad \\quad \\text{complementarity}\n",
    "  \\end{align}$$\n",
    "  where $\\circ$ is element-wise multiplication.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9a03604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   |∇Lₓ|      |∇ALₓ|     max(h)     |c|        compl     ρ\n",
      "----------------------------------------------------------------\n",
      "  1   2.98e+01   0.00e+00   4.38e+00   6.49e+00   0.00e+00  0e+00\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching zeros(::Tuple{Int64}, ::Tuple{Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  zeros(::Tuple{Vararg{Union{Integer, AbstractUnitRange}, N} where N}) at array.jl:500\n\u001b[0m  zeros(\u001b[91m::Type{T}\u001b[39m, ::Tuple{Vararg{Integer, N}}) where {T, N} at array.jl:502\n\u001b[0m  zeros(\u001b[91m::Type{T}\u001b[39m, ::Tuple{Vararg{Union{Integer, Base.OneTo}, N}}) where {T, N} at array.jl:501",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching zeros(::Tuple{Int64}, ::Tuple{Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  zeros(::Tuple{Vararg{Union{Integer, AbstractUnitRange}, N} where N}) at array.jl:500\n\u001b[0m  zeros(\u001b[91m::Type{T}\u001b[39m, ::Tuple{Vararg{Integer, N}}) where {T, N} at array.jl:502\n\u001b[0m  zeros(\u001b[91m::Type{T}\u001b[39m, ::Tuple{Vararg{Union{Integer, Base.OneTo}, N}}) where {T, N} at array.jl:501",
      "",
      "Stacktrace:",
      "  [1] mask_matrix(qp::NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, μ::Vector{Float64}, ρ::Int64)",
      "    @ Main ./In[19]:36",
      "  [2] augmented_lagrangian(qp::NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, λ::Vector{Float64}, μ::Vector{Float64}, ρ::Int64)",
      "    @ Main ./In[19]:50",
      "  [3] (::var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}})(dx::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}})",
      "    @ Main ./In[19]:86",
      "  [4] vector_mode_dual_eval!(f::var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}}, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/apiutils.jl:37",
      "  [5] vector_mode_gradient(f::var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/gradient.jl:106",
      "  [6] gradient(f::Function, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}}, ::Val{false})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/gradient.jl:19",
      "  [7] (::ForwardDiff.var\"#112#113\"{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, ForwardDiff.HessianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}})(y::Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/hessian.jl:16",
      "  [8] vector_mode_dual_eval!(f::ForwardDiff.var\"#112#113\"{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, ForwardDiff.HessianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}}, cfg::ForwardDiff.JacobianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}, x::Vector{Float64})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/apiutils.jl:37",
      "  [9] vector_mode_jacobian(f::ForwardDiff.var\"#112#113\"{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, ForwardDiff.HessianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}}, x::Vector{Float64}, cfg::ForwardDiff.JacobianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/jacobian.jl:148",
      " [10] jacobian(f::Function, x::Vector{Float64}, cfg::ForwardDiff.JacobianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}, ::Val{false})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/jacobian.jl:21",
      " [11] hessian(f::Function, x::Vector{Float64}, cfg::ForwardDiff.HessianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}, ::Val{true})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/hessian.jl:17",
      " [12] hessian(f::Function, x::Vector{Float64}, cfg::ForwardDiff.HessianConfig{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}, 10}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var\"#21#23\"{NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}}, Float64}, Float64, 10}}}) (repeats 2 times)",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QdStj/src/hessian.jl:15",
      " [13] solve_qp(qp::NamedTuple{(:Q, :q, :A, :b, :G, :h), Tuple{Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}}; verbose::Bool, max_iters::Int64, tol::Float64)",
      "    @ Main ./In[19]:86",
      " [14] top-level scope",
      "    @ In[19]:110"
     ]
    }
   ],
   "source": [
    "# TODO: read below\n",
    "# NOTE: DO NOT USE A WHILE LOOP ANYWHERE\n",
    "\"\"\"\n",
    "The data for the QP is stored in `qp` the following way:\n",
    "    @load joinpath(@__DIR__, \"qp_data.jld2\") qp \n",
    "\n",
    "which is a NamedTuple, where\n",
    "    Q, q, A, b, G, h = qp.Q, qp.q, qp.A, qp.b, qp.G, qp.h\n",
    "\n",
    "contains all of the problem data you will need for the QP.\n",
    "\n",
    "Your job is to make the following function \n",
    "    \n",
    "    x, λ, μ = solve_qp(qp; verbose = true, max_iters = 100, tol = 1e-8)\n",
    "\n",
    "You can use (or not use) any of the additional functions:\n",
    "You can use (or not use) any of the additional functions:\n",
    "You can use (or not use) any of the additional functions:\n",
    "You can use (or not use) any of the additional functions:\n",
    "\n",
    "as long as solve_qp works. \n",
    "\"\"\"\n",
    "function cost(qp::NamedTuple, x::Vector)::Real\n",
    "    0.5*x'*qp.Q*x + dot(qp.q,x)\n",
    "end\n",
    "function c_eq(qp::NamedTuple, x::Vector)::Vector\n",
    "    qp.A*x - qp.b \n",
    "end\n",
    "function h_ineq(qp::NamedTuple, x::Vector)::Vector\n",
    "    qp.G*x - qp.h\n",
    "end\n",
    "\n",
    "function mask_matrix(qp::NamedTuple, x::Vector, μ::Vector, ρ::Real)::Matrix\n",
    "    ineq = h_ineq(qp,x)\n",
    "    n = size(μ)\n",
    "    I = zeros(n,n)\n",
    "    for i = 1:size(μ)\n",
    "        if (((ineq[i]) < 0) && (μ[i]) == 0 ) \n",
    "            I[i,i] = 0\n",
    "        else\n",
    "            I[i,i] = ρ\n",
    "        end\n",
    "    end\n",
    "    return I   \n",
    "    error(\"not implemented\")\n",
    "end\n",
    "        \n",
    "function augmented_lagrangian(qp::NamedTuple, x::Vector, λ::Vector, μ::Vector, ρ::Real)::Real\n",
    "            \n",
    "    Lp = cost(qp,x) + λ'*c_eq(qp,x)+ μ'*(h_ineq(qp,x)) + 0.5*ρ*(c_eq(qp,x))'*(c_eq(qp,x)) + 0.5*(h_ineq(qp,x))'*(mask_matrix(qp,x,μ,ρ))*(h_ineq(qp,x))\n",
    "    \n",
    "    return Lp\n",
    "            \n",
    "    error(\"not implemented\")\n",
    "end\n",
    "        \n",
    "function logging(qp::NamedTuple, main_iter::Int, AL_gradient::Vector, x::Vector, λ::Vector, μ::Vector, ρ::Real)\n",
    "    # TODO: stationarity norm\n",
    "    stationarity_norm = norm(qp.Q*x + qp.q + (qp.A)'*(λ) + (qp.G)'*μ) # fill this in \n",
    "    @printf(\"%3d  % 7.2e  % 7.2e  % 7.2e  % 7.2e  % 7.2e  %5.0e\\n\",\n",
    "          main_iter, stationarity_norm, norm(AL_gradient), maximum(h_ineq(qp,x)),\n",
    "          norm(c_eq(qp,x),Inf), abs(dot(μ,h_ineq(qp,x))), ρ)\n",
    "end\n",
    "function solve_qp(qp; verbose = true, max_iters = 100, tol = 1e-8)\n",
    "    x = zeros(length(qp.q))\n",
    "    λ = zeros(length(qp.b))\n",
    "    μ = zeros(length(qp.h))\n",
    "    ρ=1\n",
    "    if verbose\n",
    "        @printf \"iter   |∇Lₓ|      |∇ALₓ|     max(h)     |c|        compl     ρ\\n\"\n",
    "        @printf \"----------------------------------------------------------------\\n\"\n",
    "    end\n",
    "    \n",
    "    # TODO:\n",
    "    for main_iter = 1:max_iters \n",
    "        if verbose\n",
    "            logging(qp, main_iter, zeros(1), x, λ, μ, 0.0)\n",
    "        end\n",
    "        \n",
    "        for i in 1:100\n",
    "#             residual_func = FD.gradient(dx -> augmented_lagrangian(qp,dx , λ, μ,ρ ), x)\n",
    "#             norm_r = norm(FD.gradient(dx -> augmented_lagrangian(qp,dx, λ, μ,ρ ), x)))\n",
    "#             if(norm_r) < 1e-10 \n",
    "#                 break\n",
    "#             end\n",
    "            A = FD.hessian(dx -> augmented_lagrangian(qp,dx ,λ, μ,ρ ), x)\n",
    "            b = -FD.gradient(dx -> augmented_lagrangian(qp,dx , λ, μ,ρ ), x)\n",
    "            del_x = A\\b\n",
    "            x = x + del_x                           \n",
    "        end\n",
    "        \n",
    "        λ = λ + ρ*c_eq(qp,x)\n",
    "        μ = max(0,μ + ρ*h_ineq(qp,x) )          \n",
    "        ρ = ρ * 10\n",
    "        \n",
    "        conv1 = norm(c_eq(qp,x),Inf)\n",
    "        conv2 = max(0,max(h_ineq(qp,x)))\n",
    "        \n",
    "        \n",
    "        # TODO: convergence criteria based on tol \n",
    "        if (conv1 < tol && conv2<tol) \n",
    "            return x, λ, μ\n",
    "        end\n",
    "    end\n",
    "    error(\"qp solver did not converge\")\n",
    "end\n",
    "let \n",
    "    # example solving qp \n",
    "    @load joinpath(@__DIR__, \"qp_data.jld2\") qp \n",
    "    x, λ, μ = solve_qp(qp; verbose = true, tol = 1e-8)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f0be",
   "metadata": {},
   "source": [
    "## QP Solver test (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48825c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 points \n",
    "using Test \n",
    "@testset \"qp solver\" begin \n",
    "    @load joinpath(@__DIR__, \"qp_data.jld2\") qp \n",
    "    x, λ, μ = solve_qp(qp; verbose = true, max_iters = 100, tol = 1e-6)\n",
    "    \n",
    "    @load joinpath(@__DIR__, \"qp_solutions.jld2\") qp_solutions\n",
    "    @test norm(x - qp_solutions.x,Inf)<1e-3;\n",
    "    @test norm(λ - qp_solutions.λ,Inf)<1e-3;\n",
    "    @test norm(μ - qp_solutions.μ,Inf)<1e-3;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d469b3",
   "metadata": {},
   "source": [
    "# Simulating a Falling Brick with QPs\n",
    "In this question we'll be simulating a brick falling and sliding on ice in 2D. You will show that this problem can be formulated as a QP, which you will solve using an Augmented Lagrangian method.\n",
    "\n",
    "## The Dynamics\n",
    "The dynamics of the brick can be written in continuous time as\n",
    "$$ M \\dot{v}  + M g = J^T \\lambda \\\\ \\text{ where } M = mI_{2\\times 2}, \\; g = \\begin{bmatrix} 0 \\\\ 9.81 \\end{bmatrix},\\; J = \\begin{bmatrix} 0 & 1 \\end{bmatrix} $$\n",
    "and $\\lambda \\in \\mathbb{R}$ is the normal force. The velocity $v \\in \\mathbb{R}^2$ and position $q \\in \\mathbb{R}^2$ are composed of the horizontal and vertical components.\n",
    "\n",
    "We can discretize the dynamics with backward Euler:\n",
    "$$ \\begin{bmatrix} v_{k+1} \\\\ q_{k+1} \\end{bmatrix} = \\begin{bmatrix} v_k \\\\ q_k \\end{bmatrix}\n",
    "+ \\Delta t \\cdot \\begin{bmatrix} \\frac{1}{m} J^T \\lambda_{k+1} - g \\\\ v_{k+1} \\end{bmatrix}$$\n",
    "\n",
    "We also have the following contact constraints:\n",
    "$$ \\begin{align}\n",
    "J q_{k+1} &\\geq 0 &&\\text{(don't fall through the ice)} \\\\\n",
    "\\lambda_{k+1} &\\geq 0 &&\\text{(normal forces only push, not pull)} \\\\\n",
    "\\lambda_{k+1} J q_{k+1} &= 0 &&\\text{(no force at a distance)}\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82898d8b",
   "metadata": {},
   "source": [
    "## Part (a): QP formulation (5 pts)\n",
    "Show that these discrete-time dynamics are equivalent to the following QP by writing down the KKT conditions.\n",
    "\n",
    "$$ \\begin{align}\n",
    "    &\\text{minimize}_{v_{k+1}} && \\frac{1}{2} v_{k+1}^T M v_{k+1} + [M (\\Delta t \\cdot g - v_k)]^Tv_{k+1} \\\\\n",
    "    &\\text{subject to} && -J(q_k + \\Delta t \\cdot v_{k+1}) \\leq 0 \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcacf03",
   "metadata": {},
   "source": [
    "**TASK**: Write down the KKT conditions for the optimization problem above, and show that it's equivalent to the dynamics problem stated previously. Use LaTeX markdown.\n",
    "\n",
    "**PUT ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8348c7f",
   "metadata": {},
   "source": [
    "## Brick Simulation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "function brick_simulation_qp(q, v; mass = 1, Δt = 0.01)\n",
    "    \n",
    "    # TODO: fill in the QP problem data for a simulation step \n",
    "    # fill in Q, q, G, h, but leave A, b the same \n",
    "    # this is because there are no equality constraints in this qp \n",
    "    \n",
    "    qp = (\n",
    "        Q = zeros(2,2), \n",
    "        q = zeros(2),\n",
    "        A = zeros(0,2), # don't edit this\n",
    "        b = zeros(0),   # don't edit this \n",
    "        G = zeros(1,2),\n",
    "        h = zeros(1)\n",
    "    )\n",
    "    \n",
    "    return qp \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"brick qp\" begin \n",
    "    \n",
    "    q = randn(2)\n",
    "    v = randn(2)\n",
    "    \n",
    "    qp = brick_simulation_qp(q,v)\n",
    "    \n",
    "    # check all the types to make sure they're right\n",
    "    qp.Q::Matrix{Float64}\n",
    "    qp.q::Vector{Float64}\n",
    "    qp.A::Matrix{Float64}\n",
    "    qp.b::Vector{Float64}\n",
    "    qp.G::Matrix{Float64}\n",
    "    qp.h::Vector{Float64}\n",
    "    \n",
    "    @test size(qp.Q) == (2,2)\n",
    "    @test size(qp.q) == (2,)\n",
    "    @test size(qp.A) == (0,2)\n",
    "    @test size(qp.b) == (0,)\n",
    "    @test size(qp.G) == (1,2)\n",
    "    @test size(qp.h) == (1,)\n",
    "    \n",
    "    @test abs(tr(qp.Q) - 2) < 1e-10\n",
    "    @test norm(qp.q - [-2.0, 3.0981]) < 1e-10 \n",
    "    @test norm(qp.G - [0 -.01]) < 1e-10 \n",
    "    @test abs(qp.h[1] -3) < 1e-10\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42288ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"animate_brick.jl\"))\n",
    "let \n",
    "    \n",
    "    dt = 0.01 \n",
    "    T = 3.0 \n",
    "    \n",
    "    t_vec = 0:dt:T\n",
    "    N = length(t_vec)\n",
    "    \n",
    "    qs = [zeros(2) for i = 1:N]\n",
    "    vs = [zeros(2) for i = 1:N]\n",
    "    \n",
    "    qs[1] = [0, 1.0]\n",
    "    vs[1] = [1, 4.5]\n",
    "    \n",
    "    # TODO: simulate the brick by forming and solving a qp \n",
    "    # at each timestep. Your QP should solve for vs[k+1], and\n",
    "    # you should use this to update qs[k+1]\n",
    "\n",
    "    \n",
    "    xs = [q[1] for q in qs]\n",
    "    ys = [q[2] for q in qs]\n",
    "    \n",
    "    @show @test abs(maximum(ys)-2)<1e-1\n",
    "    @show @test minimum(ys) > -1e-2\n",
    "    @show @test abs(xs[end] - 3) < 1e-2\n",
    "    \n",
    "    xdot = diff(xs)/dt\n",
    "    @show @test maximum(xdot) < 1.0001\n",
    "    @show @test minimum(xdot) > 0.9999\n",
    "    @show @test ys[110] > 1e-2\n",
    "    @show @test abs(ys[111]) < 1e-2\n",
    "    @show @test abs(ys[112]) < 1e-2\n",
    "    \n",
    "    display(plot(xs, ys, ylabel = \"y (m)\", xlabel = \"x (m)\"))\n",
    "    \n",
    "    animate_brick(qs)\n",
    "    \n",
    "    \n",
    "    \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
